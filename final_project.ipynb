{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a497dff3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:11.017697Z",
     "iopub.status.busy": "2024-10-24T11:43:11.017229Z",
     "iopub.status.idle": "2024-10-24T11:43:38.324914Z",
     "shell.execute_reply": "2024-10-24T11:43:38.323883Z"
    },
    "papermill": {
     "duration": 27.316044,
     "end_time": "2024-10-24T11:43:38.327404",
     "exception": false,
     "start_time": "2024-10-24T11:43:11.011360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\r\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from vaderSentiment) (2.32.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->vaderSentiment) (2024.8.30)\r\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: vaderSentiment\r\n",
      "Successfully installed vaderSentiment-3.3.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from PIL import Image, ImageStat\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218645ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:38.338951Z",
     "iopub.status.busy": "2024-10-24T11:43:38.338382Z",
     "iopub.status.idle": "2024-10-24T11:43:38.467099Z",
     "shell.execute_reply": "2024-10-24T11:43:38.466220Z"
    },
    "papermill": {
     "duration": 0.136483,
     "end_time": "2024-10-24T11:43:38.469178",
     "exception": false,
     "start_time": "2024-10-24T11:43:38.332695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file paths...\n",
      "Loading data...\n",
      "Training dataset size: (6431, 3)\n",
      "Test dataset size: (1891, 2)\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "print(\"Loading file paths...\")\n",
    "TRAIN_CSV = '/kaggle/input/deep-learning-for-computer-vision-and-nlp-2024-10/train.csv'\n",
    "TEST_CSV = '/kaggle/input/deep-learning-for-computer-vision-and-nlp-2024-10/test.csv'\n",
    "TRAIN_IMAGES_PATH = '/kaggle/input/deep-learning-for-computer-vision-and-nlp-2024-10/images/images/train'\n",
    "TEST_IMAGES_PATH = '/kaggle/input/deep-learning-for-computer-vision-and-nlp-2024-10/images/images/test'\n",
    "\n",
    "# Loading data\n",
    "print(\"Loading data...\")\n",
    "train_data = pd.read_csv(TRAIN_CSV)\n",
    "test_data = pd.read_csv(TEST_CSV)\n",
    "print(\"Training dataset size:\", train_data.shape)\n",
    "print(\"Test dataset size:\", test_data.shape)\n",
    "\n",
    "# Filling missing values in the 'Description' column and converting to strings\n",
    "train_data['Description'] = train_data['Description'].fillna('').astype(str)\n",
    "test_data['Description'] = test_data['Description'].fillna('').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e350e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:38.479992Z",
     "iopub.status.busy": "2024-10-24T11:43:38.479711Z",
     "iopub.status.idle": "2024-10-24T11:43:38.486584Z",
     "shell.execute_reply": "2024-10-24T11:43:38.485777Z"
    },
    "papermill": {
     "duration": 0.01457,
     "end_time": "2024-10-24T11:43:38.488545",
     "exception": false,
     "start_time": "2024-10-24T11:43:38.473975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_brightness(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "        stat = ImageStat.Stat(img)\n",
    "        return stat.mean[0]  # Average brightness\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Function to extract metadata from images\n",
    "def extract_image_features(pet_id, path):\n",
    "    img_folder = f'{path}/{pet_id}'\n",
    "    if not os.path.exists(img_folder):\n",
    "        return pd.Series([0, 0, 0])  # No images\n",
    "\n",
    "    image_files = os.listdir(img_folder)\n",
    "    num_images = len(image_files)\n",
    "    avg_brightness = np.mean([calculate_brightness(f'{img_folder}/{img_file}') for img_file in image_files])\n",
    "\n",
    "    return pd.Series([1 if num_images > 0 else 0, num_images, avg_brightness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1f82651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:38.498866Z",
     "iopub.status.busy": "2024-10-24T11:43:38.498566Z",
     "iopub.status.idle": "2024-10-24T11:43:44.354068Z",
     "shell.execute_reply": "2024-10-24T11:43:44.353291Z"
    },
    "papermill": {
     "duration": 5.863061,
     "end_time": "2024-10-24T11:43:44.356252",
     "exception": false,
     "start_time": "2024-10-24T11:43:38.493191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train images for metadata...\n",
      "Processing test images for metadata...\n"
     ]
    }
   ],
   "source": [
    "# Add image metadata to the training dataset\n",
    "print(\"Processing train images for metadata...\")\n",
    "train_data[['has_image', 'num_images', 'avg_brightness']] = train_data['PetID'].apply(\n",
    "    lambda x: extract_image_features(x, TRAIN_IMAGES_PATH))\n",
    "\n",
    "# Add image metadata to the test dataset\n",
    "print(\"Processing test images for metadata...\")\n",
    "test_data[['has_image', 'num_images', 'avg_brightness']] = test_data['PetID'].apply(\n",
    "    lambda x: extract_image_features(x, TEST_IMAGES_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98d4b466",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:44.367302Z",
     "iopub.status.busy": "2024-10-24T11:43:44.367010Z",
     "iopub.status.idle": "2024-10-24T11:43:44.387461Z",
     "shell.execute_reply": "2024-10-24T11:43:44.386771Z"
    },
    "papermill": {
     "duration": 0.028002,
     "end_time": "2024-10-24T11:43:44.389264",
     "exception": false,
     "start_time": "2024-10-24T11:43:44.361262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to extract age from the description\n",
    "def extract_age(description):\n",
    "    age_search = re.search(r'\\b\\d{1,2}\\s?(months?|years?)\\b', description.lower())\n",
    "    if age_search:\n",
    "        age = age_search.group(0)\n",
    "        # Convert age to months or years\n",
    "        if 'year' in age:\n",
    "            return int(re.search(r'\\d+', age).group(0)) * 12  # Convert years to months\n",
    "        elif 'month' in age:\n",
    "            return int(re.search(r'\\d+', age).group(0))  # Keep months\n",
    "    return np.nan\n",
    "\n",
    "# Function to extract breed from the description\n",
    "def extract_breed(description):\n",
    "    breed_search = re.search(r'\\b(mixed breed|poodle|labrador|bulldog|cat|dog)\\b', description.lower())\n",
    "    if breed_search:\n",
    "        return breed_search.group(0)\n",
    "    return 'unknown'\n",
    "\n",
    "# Function to extract health status from the description\n",
    "def extract_health_status(description):\n",
    "    health_search = re.search(r'\\b(healthy|vaccinated|neutered|sick)\\b', description.lower())\n",
    "    if health_search:\n",
    "        return health_search.group(0)\n",
    "    return 'unknown'\n",
    "\n",
    "# Function to count emojis in the text\n",
    "def count_emojis(text):\n",
    "    return len([char for char in text if char in emoji.EMOJI_DATA])\n",
    "\n",
    "# Sentiment analysis using VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def extract_sentiment(description):\n",
    "    sentiment = analyzer.polarity_scores(description)\n",
    "    return pd.Series([sentiment['pos'], sentiment['neu'], sentiment['neg'], sentiment['compound']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0655bb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:44.400887Z",
     "iopub.status.busy": "2024-10-24T11:43:44.400571Z",
     "iopub.status.idle": "2024-10-24T11:43:54.810617Z",
     "shell.execute_reply": "2024-10-24T11:43:54.809651Z"
    },
    "papermill": {
     "duration": 10.417887,
     "end_time": "2024-10-24T11:43:54.812984",
     "exception": false,
     "start_time": "2024-10-24T11:43:44.395097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add new features to the training dataset\n",
    "train_data['Age'] = train_data['Description'].apply(extract_age)\n",
    "train_data['Breed'] = train_data['Description'].apply(extract_breed)\n",
    "train_data['Health_Status'] = train_data['Description'].apply(extract_health_status)\n",
    "train_data['emoji_count'] = train_data['Description'].apply(count_emojis)\n",
    "\n",
    "# Add new features to the test dataset\n",
    "test_data['Age'] = test_data['Description'].apply(extract_age)\n",
    "test_data['Breed'] = test_data['Description'].apply(extract_breed)\n",
    "test_data['Health_Status'] = test_data['Description'].apply(extract_health_status)\n",
    "test_data['emoji_count'] = test_data['Description'].apply(count_emojis)\n",
    "\n",
    "# Add sentiment analysis features (positive, neutral, negative, compound)\n",
    "train_data[['sentiment_pos', 'sentiment_neu', 'sentiment_neg', 'sentiment_compound']] = train_data['Description'].apply(\n",
    "    extract_sentiment)\n",
    "test_data[['sentiment_pos', 'sentiment_neu', 'sentiment_neg', 'sentiment_compound']] = test_data['Description'].apply(\n",
    "    extract_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34757ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:54.824308Z",
     "iopub.status.busy": "2024-10-24T11:43:54.823989Z",
     "iopub.status.idle": "2024-10-24T11:43:54.832500Z",
     "shell.execute_reply": "2024-10-24T11:43:54.831593Z"
    },
    "papermill": {
     "duration": 0.016273,
     "end_time": "2024-10-24T11:43:54.834316",
     "exception": false,
     "start_time": "2024-10-24T11:43:54.818043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate ratios of positive and negative sentiment words\n",
    "def extract_sentiment_ratios(description):\n",
    "    sentiment = analyzer.polarity_scores(description)\n",
    "    total = sentiment['pos'] + sentiment['neg'] + sentiment['neu']\n",
    "    pos_ratio = sentiment['pos'] / total if total > 0 else 0\n",
    "    neg_ratio = sentiment['neg'] / total if total > 0 else 0\n",
    "    return pd.Series([pos_ratio, neg_ratio])\n",
    "\n",
    "# Function to extract features from an image using ResNet50\n",
    "def extract_image_features_resnet(pet_id, path, model):\n",
    "    img_folder = f'{path}/{pet_id}'\n",
    "    if not os.path.exists(img_folder):\n",
    "        return np.zeros((2048,))  # ResNet50 output size\n",
    "\n",
    "    image_files = os.listdir(img_folder)\n",
    "    img_path = f'{img_folder}/{image_files[0]}'  # Use the first image\n",
    "\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(224, 224))  # Normalize image\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)  # Prepare for ResNet50\n",
    "        features = model.predict(img_data)\n",
    "        return features.flatten()  # Convert to 1D\n",
    "    except:\n",
    "        return np.zeros((2048,))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee7ba8b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:43:54.844975Z",
     "iopub.status.busy": "2024-10-24T11:43:54.844677Z",
     "iopub.status.idle": "2024-10-24T11:44:08.310371Z",
     "shell.execute_reply": "2024-10-24T11:44:08.309573Z"
    },
    "papermill": {
     "duration": 13.473811,
     "end_time": "2024-10-24T11:44:08.312805",
     "exception": false,
     "start_time": "2024-10-24T11:43:54.838994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Add sentiment ratio features to the training dataset\n",
    "train_data[['pos_ratio', 'neg_ratio']] = train_data['Description'].apply(extract_sentiment_ratios)\n",
    "\n",
    "# Add sentiment ratio features to the test dataset\n",
    "test_data[['pos_ratio', 'neg_ratio']] = test_data['Description'].apply(extract_sentiment_ratios)\n",
    "\n",
    "# Create binary feature for missing age\n",
    "train_data['Age_missing'] = train_data['Age'].isna().astype(int)\n",
    "test_data['Age_missing'] = test_data['Age'].isna().astype(int)\n",
    "\n",
    "# Replace missing ages with a special value (-1 to indicate unknown)\n",
    "train_data['Age'] = train_data['Age'].fillna(-1)\n",
    "test_data['Age'] = test_data['Age'].fillna(-1)\n",
    "\n",
    "# Encode categorical features (Breed, Health_Status) using OneHotEncoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "train_breed_health = encoder.fit_transform(train_data[['Breed', 'Health_Status']])\n",
    "test_breed_health = encoder.transform(test_data[['Breed', 'Health_Status']])\n",
    "\n",
    "# Process text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "train_text_data = vectorizer.fit_transform(train_data['Description'].fillna(''))\n",
    "test_text_data = vectorizer.transform(test_data['Description'].fillna(''))\n",
    "\n",
    "# Transfer learning: ResNet50 for image feature extraction\n",
    "resnet = ResNet50(weights='imagenet', include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37f7ecdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:44:08.326632Z",
     "iopub.status.busy": "2024-10-24T11:44:08.326296Z",
     "iopub.status.idle": "2024-10-24T11:44:08.488531Z",
     "shell.execute_reply": "2024-10-24T11:44:08.487546Z"
    },
    "papermill": {
     "duration": 0.171721,
     "end_time": "2024-10-24T11:44:08.490911",
     "exception": false,
     "start_time": "2024-10-24T11:44:08.319190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ResNet50 features for training images...\n",
      "Extracting ResNet50 features for test images...\n"
     ]
    }
   ],
   "source": [
    "# Extract ResNet50 features for training images\n",
    "print(\"Extracting ResNet50 features for training images...\")\n",
    "train_image_features = np.array(\n",
    "    [extract_image_features_resnet(pet_id, TRAIN_IMAGES_PATH, resnet) for pet_id in train_data['PetID']])\n",
    "\n",
    "# Extract ResNet50 features for test images\n",
    "print(\"Extracting ResNet50 features for test images...\")\n",
    "test_image_features = np.array(\n",
    "    [extract_image_features_resnet(pet_id, TEST_IMAGES_PATH, resnet) for pet_id in test_data['PetID']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df9c3b76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:44:08.504679Z",
     "iopub.status.busy": "2024-10-24T11:44:08.504326Z",
     "iopub.status.idle": "2024-10-24T11:44:11.171543Z",
     "shell.execute_reply": "2024-10-24T11:44:11.170529Z"
    },
    "papermill": {
     "duration": 2.676757,
     "end_time": "2024-10-24T11:44:11.173904",
     "exception": false,
     "start_time": "2024-10-24T11:44:08.497147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE to handle class imbalance...\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all features into a single feature matrix\n",
    "train_features = np.hstack([\n",
    "    train_text_data.toarray(),\n",
    "    train_data[['has_image', 'num_images', 'avg_brightness', 'Age', 'emoji_count', 'Age_missing',\n",
    "                'sentiment_pos', 'sentiment_neu', 'sentiment_neg', 'sentiment_compound', 'pos_ratio',\n",
    "                'neg_ratio']].values,\n",
    "    train_breed_health,\n",
    "    train_image_features\n",
    "])\n",
    "\n",
    "test_features = np.hstack([\n",
    "    test_text_data.toarray(),\n",
    "    test_data[['has_image', 'num_images', 'avg_brightness', 'Age', 'emoji_count', 'Age_missing',\n",
    "               'sentiment_pos', 'sentiment_neu', 'sentiment_neg', 'sentiment_compound', 'pos_ratio',\n",
    "               'neg_ratio']].values,\n",
    "    test_breed_health,\n",
    "    test_image_features\n",
    "])\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_features)\n",
    "X_val = scaler.transform(test_features)\n",
    "\n",
    "# Split training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_data['AdoptionSpeed'], test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "print(\"Applying SMOTE to handle class imbalance...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d33c2c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:44:11.187862Z",
     "iopub.status.busy": "2024-10-24T11:44:11.187500Z",
     "iopub.status.idle": "2024-10-24T11:44:52.987606Z",
     "shell.execute_reply": "2024-10-24T11:44:52.986804Z"
    },
    "papermill": {
     "duration": 41.809276,
     "end_time": "2024-10-24T11:44:52.989624",
     "exception": false,
     "start_time": "2024-10-24T11:44:11.180348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the model...\n",
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729770253.167170      71 service.cc:145] XLA service 0x7fd7b8004500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1729770253.167222      71 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1729770253.167225      71 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 63/213\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1379 - mae: 1.5225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729770256.785512      71 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 2.7266 - mae: 1.2315 - val_loss: 1.4560 - val_mae: 1.0132\n",
      "Epoch 2/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0847 - mae: 0.8370 - val_loss: 1.3586 - val_mae: 0.9673\n",
      "Epoch 3/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9145 - mae: 0.7208 - val_loss: 1.6800 - val_mae: 0.9373\n",
      "Epoch 4/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7341 - mae: 0.6344 - val_loss: 1.4180 - val_mae: 0.9721\n",
      "Epoch 5/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5249 - mae: 0.5559 - val_loss: 1.4570 - val_mae: 0.9752\n",
      "Epoch 6/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7249 - mae: 0.5465 - val_loss: 1.4159 - val_mae: 0.9538\n",
      "Epoch 7/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.4810 - mae: 0.4789 - val_loss: 1.3777 - val_mae: 0.9502\n",
      "Epoch 8/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3837 - mae: 0.4548 - val_loss: 1.3836 - val_mae: 0.9476\n",
      "Epoch 9/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3257 - mae: 0.4252 - val_loss: 1.3897 - val_mae: 0.9476\n",
      "Epoch 10/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2862 - mae: 0.3938 - val_loss: 1.4669 - val_mae: 0.9800\n",
      "Epoch 11/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2589 - mae: 0.3778 - val_loss: 1.3915 - val_mae: 0.9470\n",
      "Epoch 12/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2489 - mae: 0.3626 - val_loss: 1.4786 - val_mae: 0.9862\n",
      "Epoch 13/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2449 - mae: 0.3687 - val_loss: 1.3642 - val_mae: 0.9406\n",
      "Epoch 14/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2075 - mae: 0.3312 - val_loss: 1.3600 - val_mae: 0.9334\n",
      "Epoch 15/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2218 - mae: 0.3396 - val_loss: 1.3822 - val_mae: 0.9461\n",
      "Epoch 16/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2471 - mae: 0.3369 - val_loss: 1.3786 - val_mae: 0.9466\n",
      "Epoch 17/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1879 - mae: 0.3113 - val_loss: 1.3281 - val_mae: 0.9229\n",
      "Epoch 18/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1839 - mae: 0.3005 - val_loss: 1.3331 - val_mae: 0.9307\n",
      "Epoch 19/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1852 - mae: 0.3107 - val_loss: 1.3217 - val_mae: 0.9220\n",
      "Epoch 20/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1767 - mae: 0.2986 - val_loss: 1.3252 - val_mae: 0.9223\n",
      "Epoch 21/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1785 - mae: 0.2903 - val_loss: 1.3090 - val_mae: 0.9200\n",
      "Epoch 22/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1499 - mae: 0.2788 - val_loss: 1.3379 - val_mae: 0.9250\n",
      "Epoch 23/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1519 - mae: 0.2760 - val_loss: 1.3167 - val_mae: 0.9198\n",
      "Epoch 24/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1732 - mae: 0.2799 - val_loss: 1.3745 - val_mae: 0.9340\n",
      "Epoch 25/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1416 - mae: 0.2625 - val_loss: 1.2884 - val_mae: 0.9139\n",
      "Epoch 26/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1331 - mae: 0.2555 - val_loss: 1.3171 - val_mae: 0.9214\n",
      "Epoch 27/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1267 - mae: 0.2475 - val_loss: 1.2926 - val_mae: 0.9073\n",
      "Epoch 28/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1266 - mae: 0.2453 - val_loss: 1.2956 - val_mae: 0.9089\n",
      "Epoch 29/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1222 - mae: 0.2460 - val_loss: 1.2845 - val_mae: 0.9035\n",
      "Epoch 30/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1191 - mae: 0.2436 - val_loss: 1.2597 - val_mae: 0.9049\n",
      "Epoch 31/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1169 - mae: 0.2385 - val_loss: 1.2917 - val_mae: 0.8968\n",
      "Epoch 32/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1106 - mae: 0.2295 - val_loss: 1.2862 - val_mae: 0.8998\n",
      "Epoch 33/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1101 - mae: 0.2258 - val_loss: 1.2963 - val_mae: 0.9009\n",
      "Epoch 34/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0979 - mae: 0.2143 - val_loss: 1.3189 - val_mae: 0.9126\n",
      "Epoch 35/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1027 - mae: 0.2195 - val_loss: 1.3319 - val_mae: 0.9098\n",
      "Epoch 36/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1185 - mae: 0.2215 - val_loss: 1.3333 - val_mae: 0.9073\n",
      "Epoch 37/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0971 - mae: 0.2089 - val_loss: 1.3194 - val_mae: 0.9062\n",
      "Epoch 38/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0937 - mae: 0.1988 - val_loss: 1.3115 - val_mae: 0.8923\n",
      "Epoch 39/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1141 - mae: 0.2038 - val_loss: 1.3317 - val_mae: 0.8976\n",
      "Epoch 40/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0924 - mae: 0.1970 - val_loss: 1.3220 - val_mae: 0.9000\n",
      "Epoch 41/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1065 - mae: 0.1992 - val_loss: 1.3133 - val_mae: 0.8862\n",
      "Epoch 42/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0945 - mae: 0.1910 - val_loss: 1.3026 - val_mae: 0.8919\n",
      "Epoch 43/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0910 - mae: 0.1834 - val_loss: 1.3124 - val_mae: 0.8882\n",
      "Epoch 44/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0883 - mae: 0.1730 - val_loss: 1.2908 - val_mae: 0.8832\n",
      "Epoch 45/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0791 - mae: 0.1641 - val_loss: 1.2925 - val_mae: 0.8779\n",
      "Epoch 46/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0873 - mae: 0.1680 - val_loss: 1.3168 - val_mae: 0.8859\n",
      "Epoch 47/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0890 - mae: 0.1689 - val_loss: 1.3367 - val_mae: 0.8787\n",
      "Epoch 48/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0715 - mae: 0.1453 - val_loss: 1.3141 - val_mae: 0.8784\n",
      "Epoch 49/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0803 - mae: 0.1513 - val_loss: 1.3235 - val_mae: 0.8826\n",
      "Epoch 50/50\n",
      "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0698 - mae: 0.1435 - val_loss: 1.3382 - val_mae: 0.8830\n",
      "Evaluating the model...\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Cohen's Kappa score: 0.29031250792715113\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build a fully connected neural network for classification\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Building the model...\")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Set early stopping criteria to avoid overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(X_train_balanced, y_train_balanced, epochs=50, batch_size=32, validation_data=(X_val, y_val),\n",
    "              class_weight=class_weight_dict)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "print(\"Evaluating the model...\")\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_pred_rounded = np.round(y_val_pred).astype(int)\n",
    "y_val_pred_rounded = np.clip(y_val_pred_rounded, 1, 4)\n",
    "\n",
    "# Calculate Cohen's Kappa score to evaluate classification performance\n",
    "kappa = cohen_kappa_score(y_val, y_val_pred_rounded, weights='quadratic')\n",
    "print(f\"Cohen's Kappa score: {kappa}\")\n",
    "\n",
    "# Make predictions on train data\n",
    "predictions = model.predict(test_features)\n",
    "predictions_rounded = np.round(predictions).astype(int)\n",
    "predictions_rounded = np.clip(predictions_rounded, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c63a6dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T11:44:53.100485Z",
     "iopub.status.busy": "2024-10-24T11:44:53.100174Z",
     "iopub.status.idle": "2024-10-24T11:44:53.112600Z",
     "shell.execute_reply": "2024-10-24T11:44:53.111696Z"
    },
    "papermill": {
     "duration": 0.069417,
     "end_time": "2024-10-24T11:44:53.114611",
     "exception": false,
     "start_time": "2024-10-24T11:44:53.045194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of PetID: 1891 <class 'list'>\n",
      "Shape of predictions_rounded: (1891,) <class 'numpy.ndarray'>\n",
      "Predictions saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Ensure predictions_rounded is flattened correctly\n",
    "predictions_rounded = predictions_rounded.flatten()\n",
    "\n",
    "# Convert PetID to a list\n",
    "pet_ids = test_data['PetID'].tolist()\n",
    "\n",
    "# Debugging: Print shapes and types\n",
    "print(\"Shape of PetID:\", len(pet_ids), type(pet_ids))\n",
    "print(\"Shape of predictions_rounded:\", predictions_rounded.shape, type(predictions_rounded))\n",
    "\n",
    "# Check for dimensions\n",
    "if len(pet_ids) != len(predictions_rounded):\n",
    "    raise ValueError(\"Length mismatch: PetID and predictions_rounded must be of the same length.\")\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'PetID': pet_ids,\n",
    "    'AdoptionSpeed': predictions_rounded\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False, header=False)  # Set header=False to match the format you want\n",
    "print(\"Predictions saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9778966,
     "sourceId": 86259,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 107.744351,
   "end_time": "2024-10-24T11:44:55.984620",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-24T11:43:08.240269",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
